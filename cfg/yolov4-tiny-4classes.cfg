[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=64
subdivisions=4
#width=128
#height=128
#batch=64
#subdivisions=2
width=256
height=256
channels=3
random=1
blur=1
min_crop=10
max_crop=120
aspect=.2
#letter_box=0
#cutmix=0
#mosaic=0
#mosaic_bound=1
#adversarial_lr=1.0
#attention=1
#gaussian_noise=0

momentum=0.8
decay=0.0005
angle=180
saturation = 0.20
exposure = 0.82
hue=.3

burn_in=1000
decay=0.0005
learning_rate=0.0001
max_batches = 50000
policy=steps
steps=6000, 9000
scales=.5,.5
# random sgdr steps step sig exp poly
#steps=3000,9000
scales=.2,.2
adam=1


[convolutional]
batch_normalize=1
filters=32
size=3
stride=2
pad=1
activation=leaky





[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[route]
layers=-1
groups=2
group_id=1

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[route]
layers = -1,-2

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -6,-1

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[route]
layers=-1
groups=2
group_id=1

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[route]
layers = -1,-2

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -6,-1

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[route]
layers=-1
groups=2
group_id=1

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[route]
layers = -1,-2

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -6,-1

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

##################################

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=27
activation=linear



[yolo]
mask = 3,4,5
#anchors =  26,109,  37,136,  35,185,  54,184,  82,246, 152,251
anchors =  18, 38,  26, 89,  28,190,  40,133,  60,216, 126,248
#anchors =  29, 63,  42,157,  63,209,  76,312, 108,372, 226,402



classes=4
num=6
jitter=.3
scale_x_y = 1.05
cls_normalizer=1.0
iou_normalizer=0.05
iou_loss=ciou
ignore_thresh = .7
truth_thresh = 1
random=1
resize=1.5
nms_kind=diounms
beta_nms=0.6

[route]
layers = -4

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 23

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=27
activation=linear

[yolo]
mask = 0,1,2
#anchors =  26,109,  37,136,  35,185,  54,184,  82,246, 152,251
anchors =  18, 38,  26, 89,  28,190,  40,133,  60,216, 126,248
#anchors =  29, 63,  42,157,  63,209,  76,312, 108,372, 226,402
classes=4
num=6
jitter=.3
scale_x_y = 1.05
cls_normalizer=1.0
iou_normalizer=0.05
iou_loss=ciou
ignore_thresh = .7
truth_thresh = 1
random=1
resize=1.5
nms_kind=diounms
beta_nms=0.6
